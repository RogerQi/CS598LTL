{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MetaHDFDataset\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataset = pickle.load(open('pushing.pickle',\"rb\"))\n",
    "\n",
    "N_of_metatrain_trajs = len(metadataset.MTRAIN) #240\n",
    "N_of_metaval_trajs = len(metadataset.MVAL) #30\n",
    "N_of_metatest_trajs = len(metadataset.MTEST) #30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "# Hyperparameters\n",
    "traj_batch = 5\n",
    "n_epochs = 10000\n",
    "hidden_size = 800\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "model_type = 'gru'\n",
    "print_every = 50\n",
    "plot_every = 50\n",
    "bidir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, input, target, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - rnn: model\n",
    "    - input: K input trajectory of pusher and N obejcts (K,N+1,timesteps,6) a list of lists of numpy arrays\n",
    "    - target: target predictions (K,N,timesteps, 3)\n",
    "    - optimizer: rnn model optimizer\n",
    "    - criterion: loss function\n",
    "    \n",
    "    Returns:\n",
    "    - loss: computed loss value as python float\n",
    "    \"\"\"\n",
    "\n",
    "    k = len(input)\n",
    "    timesteps,_ = np.shape(input[0][0])\n",
    "    hidden_layer = rnn.init_hidden(timesteps,device)\n",
    "    rnn.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0.\n",
    "    \n",
    "    for traj in range(k):\n",
    "        loss_tmp = 0.\n",
    "        for o in range(len(input[traj])):\n",
    "            output, hidden_layer = rnn(torch.from_numpy(input[traj][o]).to(device),hidden_layer)\n",
    "            if o > 0:\n",
    "                loss_tmp += criterion(output,torch.from_numpy(target[traj][o-1]).float().to(device))\n",
    "        loss += loss_tmp/len(input[traj])\n",
    "            \n",
    "    loss = loss/k\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "\n",
    "def generate_random_data(N_of_trajs,all_trajs):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    ---------\n",
    "    generates train and val input and output data in numpy array\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    indeces = np.random.choice(len(all_trajs),N_of_trajs)\n",
    "    train_input_data = []\n",
    "    train_output_data = []\n",
    "    val_input_data = []\n",
    "    val_output_data = []\n",
    "    \n",
    "    for i in indeces:\n",
    "        train_input_traj = []\n",
    "        train_output_traj = []\n",
    "        val_input_traj = []\n",
    "        val_output_traj = []\n",
    "        \n",
    "        timesteps,d = all_trajs[i].TrainInput.shape\n",
    "        N = int(d/6)\n",
    "        for j in range(N):\n",
    "            if j == 0:\n",
    "#                 print(all_trajs[i].TrainInput[:,-6:].dtype)\n",
    "#                 exit()\n",
    "                train_input_traj.append(all_trajs[i].TrainInput[:,-6:])\n",
    "                train_output_traj.append(all_trajs[i].TrainOutput[:,-3:])\n",
    "                val_input_traj.append(all_trajs[i].ValInput[:,-6:])\n",
    "                val_output_traj.append(all_trajs[i].ValOutput[:,-3:])\n",
    "            else:\n",
    "                train_input_traj.append(all_trajs[i].TrainInput[:,(j-1)*6:j*6])\n",
    "                train_output_traj.append(all_trajs[i].TrainOutput[:,(j-1)*3:j*3])\n",
    "                val_input_traj.append(all_trajs[i].ValInput[:,(j-1)*6:j*6])\n",
    "                val_output_traj.append(all_trajs[i].ValOutput[:,(j-1)*3:j*3])\n",
    "        train_input_data.append(train_input_traj)\n",
    "        train_output_data.append(train_output_traj)\n",
    "        val_input_data.append(val_input_traj)\n",
    "        val_output_data.append(val_output_traj)\n",
    "        \n",
    "    return train_input_data,train_output_data,val_input_data,val_output_data\n",
    "            \n",
    "def eval_test(rnn, input, target):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ---------------\n",
    "    inp: traj_batch x N_objects(including pusher) x timesteps x 6\n",
    "    target: traj_batch x N_objects(including pusher) x timesteps x 3\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        k = len(input)\n",
    "        timesteps,_ = np.shape(input[0][0])\n",
    "        hidden_layer = rnn.init_hidden(timesteps,device)    \n",
    "        loss = 0.\n",
    "    \n",
    "        for traj in range(k):\n",
    "            loss_tmp = 0.\n",
    "            for o in range(len(input[traj])):\n",
    "                output, hidden_layer = rnn(torch.from_numpy(input[traj][o]).to(device),hidden_layer)\n",
    "                if o > 0:\n",
    "                    loss_tmp += criterion(output,torch.from_numpy(target[traj][o-1]).to(device))\n",
    "            loss += loss_tmp/len(input[traj])\n",
    "\n",
    "        loss = loss/k\n",
    "    return loss\n",
    "\n",
    "def eval_test_baseline(target):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ---------------\n",
    "    inp: traj_batch x N_objects(including pusher) x timesteps x 6\n",
    "    target: traj_batch x N_objects(including pusher) x timesteps x 3\n",
    "    \"\"\"\n",
    "    k = len(target)\n",
    "    loss = 0.\n",
    "\n",
    "    for traj in range(k):\n",
    "        loss_tmp = 0.\n",
    "        timesteps,_ = np.shape(target[0][0])\n",
    "        for o in range(len(target[traj])):\n",
    "            if o > 0:\n",
    "                first_state = target[traj][o-1][0]\n",
    "                baseline_output = np.tile(first_state,(timesteps,1))\n",
    "                loss_tmp += criterion(torch.from_numpy(baseline_output).to(device),torch.from_numpy(target[traj][o-1]).to(device))\n",
    "        loss += loss_tmp/len(target[traj])\n",
    "\n",
    "        loss = loss/k\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 epochs...\n",
      "[0m 2s (50 0%) train loss: 0.1224, test_loss: 0.1084]\n",
      "[0m 5s (100 1%) train loss: 0.1449, test_loss: 0.1423]\n",
      "[0m 7s (150 1%) train loss: 0.4445, test_loss: 0.4020]\n",
      "[0m 10s (200 2%) train loss: 0.3092, test_loss: 0.3145]\n",
      "[0m 12s (250 2%) train loss: 0.0834, test_loss: 0.0837]\n",
      "[0m 15s (300 3%) train loss: 0.3752, test_loss: 0.2706]\n",
      "[0m 17s (350 3%) train loss: 0.5066, test_loss: 0.4809]\n",
      "[0m 20s (400 4%) train loss: 0.4071, test_loss: 0.2956]\n",
      "[0m 23s (450 4%) train loss: 0.4046, test_loss: 0.3919]\n",
      "[0m 25s (500 5%) train loss: 0.0922, test_loss: 0.0921]\n",
      "[0m 28s (550 5%) train loss: 0.1723, test_loss: 0.1525]\n",
      "[0m 30s (600 6%) train loss: 0.0986, test_loss: 0.1051]\n",
      "[0m 33s (650 6%) train loss: 0.0805, test_loss: 0.0739]\n",
      "[0m 35s (700 7%) train loss: 0.2077, test_loss: 0.1830]\n",
      "[0m 38s (750 7%) train loss: 0.4090, test_loss: 0.3697]\n",
      "[0m 40s (800 8%) train loss: 0.1807, test_loss: 0.1617]\n",
      "[0m 43s (850 8%) train loss: 0.2684, test_loss: 0.2793]\n",
      "[0m 45s (900 9%) train loss: 0.1119, test_loss: 0.1115]\n",
      "[0m 48s (950 9%) train loss: 0.2033, test_loss: 0.1645]\n",
      "[0m 50s (1000 10%) train loss: 0.1627, test_loss: 0.1670]\n",
      "[0m 53s (1050 10%) train loss: 0.0768, test_loss: 0.0865]\n",
      "[0m 55s (1100 11%) train loss: 0.2921, test_loss: 0.2830]\n",
      "[0m 58s (1150 11%) train loss: 0.2082, test_loss: 0.1400]\n",
      "[1m 1s (1200 12%) train loss: 0.0622, test_loss: 0.0610]\n",
      "[1m 3s (1250 12%) train loss: 0.3228, test_loss: 0.2977]\n",
      "[1m 6s (1300 13%) train loss: 0.1283, test_loss: 0.1974]\n",
      "[1m 8s (1350 13%) train loss: 0.3081, test_loss: 0.2708]\n",
      "[1m 11s (1400 14%) train loss: 0.1692, test_loss: 0.1783]\n",
      "[1m 13s (1450 14%) train loss: 0.1123, test_loss: 0.1054]\n",
      "[1m 16s (1500 15%) train loss: 0.1406, test_loss: 0.1180]\n",
      "[1m 18s (1550 15%) train loss: 0.2321, test_loss: 0.1204]\n",
      "[1m 21s (1600 16%) train loss: 0.1786, test_loss: 0.1819]\n",
      "[1m 23s (1650 16%) train loss: 0.0900, test_loss: 0.1554]\n",
      "[1m 26s (1700 17%) train loss: 0.1871, test_loss: 0.1604]\n",
      "[1m 28s (1750 17%) train loss: 0.0450, test_loss: 0.0507]\n",
      "[1m 31s (1800 18%) train loss: 0.1674, test_loss: 0.1605]\n",
      "[1m 33s (1850 18%) train loss: 0.1301, test_loss: 0.1109]\n",
      "[1m 36s (1900 19%) train loss: 0.1157, test_loss: 0.1031]\n",
      "[1m 39s (1950 19%) train loss: 0.1233, test_loss: 0.1145]\n",
      "[1m 41s (2000 20%) train loss: 0.1515, test_loss: 0.1191]\n",
      "[1m 44s (2050 20%) train loss: 0.0274, test_loss: 0.0293]\n",
      "[1m 46s (2100 21%) train loss: 0.0842, test_loss: 0.0911]\n",
      "[1m 49s (2150 21%) train loss: 0.1349, test_loss: 0.1190]\n",
      "[1m 52s (2200 22%) train loss: 0.1006, test_loss: 0.1062]\n",
      "[1m 54s (2250 22%) train loss: 0.0705, test_loss: 0.0722]\n",
      "[1m 57s (2300 23%) train loss: 0.1049, test_loss: 0.1123]\n",
      "[1m 59s (2350 23%) train loss: 0.0537, test_loss: 0.0626]\n",
      "[2m 2s (2400 24%) train loss: 0.0191, test_loss: 0.0220]\n",
      "[2m 4s (2450 24%) train loss: 0.1061, test_loss: 0.1079]\n",
      "[2m 7s (2500 25%) train loss: 0.0595, test_loss: 0.0431]\n",
      "[2m 10s (2550 25%) train loss: 0.0353, test_loss: 0.0411]\n",
      "[2m 12s (2600 26%) train loss: 0.0925, test_loss: 0.0697]\n",
      "[2m 15s (2650 26%) train loss: 0.0330, test_loss: 0.0327]\n",
      "[2m 17s (2700 27%) train loss: 0.2460, test_loss: 0.1771]\n",
      "[2m 20s (2750 27%) train loss: 0.0911, test_loss: 0.0686]\n",
      "[2m 23s (2800 28%) train loss: 0.3195, test_loss: 0.1594]\n",
      "[2m 25s (2850 28%) train loss: 0.0545, test_loss: 0.0519]\n",
      "[2m 27s (2900 28%) train loss: 0.0700, test_loss: 0.0596]\n",
      "[2m 30s (2950 29%) train loss: 0.0798, test_loss: 0.0791]\n",
      "[2m 33s (3000 30%) train loss: 0.0518, test_loss: 0.0525]\n",
      "[2m 35s (3050 30%) train loss: 0.0543, test_loss: 0.0585]\n",
      "[2m 38s (3100 31%) train loss: 0.0453, test_loss: 0.0413]\n",
      "[2m 41s (3150 31%) train loss: 0.0281, test_loss: 0.0411]\n",
      "[2m 43s (3200 32%) train loss: 0.1381, test_loss: 0.1175]\n",
      "[2m 46s (3250 32%) train loss: 0.0197, test_loss: 0.0218]\n",
      "[2m 48s (3300 33%) train loss: 0.0204, test_loss: 0.0206]\n",
      "[2m 51s (3350 33%) train loss: 0.1139, test_loss: 0.1284]\n",
      "[2m 53s (3400 34%) train loss: 0.0440, test_loss: 0.0454]\n",
      "[2m 56s (3450 34%) train loss: 0.0265, test_loss: 0.0341]\n",
      "[2m 58s (3500 35%) train loss: 0.2475, test_loss: 0.2365]\n",
      "[3m 1s (3550 35%) train loss: 0.0779, test_loss: 0.0695]\n",
      "[3m 4s (3600 36%) train loss: 0.0463, test_loss: 0.0408]\n",
      "[3m 6s (3650 36%) train loss: 0.0733, test_loss: 0.0714]\n",
      "[3m 9s (3700 37%) train loss: 0.0479, test_loss: 0.0440]\n",
      "[3m 11s (3750 37%) train loss: 0.0229, test_loss: 0.0259]\n",
      "[3m 14s (3800 38%) train loss: 0.0455, test_loss: 0.0396]\n",
      "[3m 16s (3850 38%) train loss: 0.0412, test_loss: 0.0389]\n",
      "[3m 19s (3900 39%) train loss: 0.0382, test_loss: 0.0386]\n",
      "[3m 21s (3950 39%) train loss: 0.0378, test_loss: 0.0376]\n",
      "[3m 24s (4000 40%) train loss: 0.0287, test_loss: 0.0322]\n",
      "[3m 27s (4050 40%) train loss: 0.0317, test_loss: 0.0229]\n",
      "[3m 29s (4100 41%) train loss: 0.2187, test_loss: 0.1942]\n",
      "[3m 32s (4150 41%) train loss: 0.0574, test_loss: 0.0518]\n",
      "[3m 34s (4200 42%) train loss: 0.0249, test_loss: 0.0273]\n",
      "[3m 37s (4250 42%) train loss: 0.0200, test_loss: 0.0225]\n",
      "[3m 39s (4300 43%) train loss: 0.0216, test_loss: 0.0266]\n",
      "[3m 42s (4350 43%) train loss: 0.0643, test_loss: 0.0667]\n",
      "[3m 44s (4400 44%) train loss: 0.1056, test_loss: 0.1023]\n",
      "[3m 47s (4450 44%) train loss: 0.0393, test_loss: 0.0396]\n",
      "[3m 50s (4500 45%) train loss: 0.0332, test_loss: 0.0292]\n",
      "[3m 52s (4550 45%) train loss: 0.0309, test_loss: 0.0299]\n",
      "[3m 54s (4600 46%) train loss: 0.0240, test_loss: 0.0251]\n",
      "[3m 57s (4650 46%) train loss: 0.0223, test_loss: 0.0232]\n",
      "[4m 0s (4700 47%) train loss: 0.0633, test_loss: 0.0549]\n",
      "[4m 2s (4750 47%) train loss: 0.0478, test_loss: 0.0401]\n",
      "[4m 5s (4800 48%) train loss: 0.0183, test_loss: 0.0172]\n",
      "[4m 7s (4850 48%) train loss: 0.0822, test_loss: 0.0691]\n",
      "[4m 10s (4900 49%) train loss: 0.0735, test_loss: 0.0790]\n",
      "[4m 12s (4950 49%) train loss: 0.0382, test_loss: 0.0357]\n",
      "[4m 15s (5000 50%) train loss: 0.0486, test_loss: 0.0451]\n",
      "[4m 17s (5050 50%) train loss: 0.0369, test_loss: 0.0326]\n",
      "[4m 20s (5100 51%) train loss: 0.0238, test_loss: 0.0258]\n",
      "[4m 23s (5150 51%) train loss: 0.0597, test_loss: 0.0486]\n",
      "[4m 25s (5200 52%) train loss: 0.0652, test_loss: 0.0406]\n",
      "[4m 28s (5250 52%) train loss: 0.0197, test_loss: 0.0161]\n",
      "[4m 30s (5300 53%) train loss: 0.0208, test_loss: 0.0242]\n",
      "[4m 33s (5350 53%) train loss: 0.0165, test_loss: 0.0201]\n",
      "[4m 35s (5400 54%) train loss: 0.0434, test_loss: 0.0205]\n",
      "[4m 38s (5450 54%) train loss: 0.0179, test_loss: 0.0165]\n",
      "[4m 40s (5500 55%) train loss: 0.0443, test_loss: 0.0406]\n",
      "[4m 43s (5550 55%) train loss: 0.0281, test_loss: 0.0228]\n",
      "[4m 46s (5600 56%) train loss: 0.0133, test_loss: 0.0142]\n",
      "[4m 48s (5650 56%) train loss: 0.0497, test_loss: 0.0537]\n",
      "[4m 51s (5700 56%) train loss: 0.0254, test_loss: 0.0290]\n",
      "[4m 53s (5750 57%) train loss: 0.0574, test_loss: 0.0522]\n",
      "[4m 56s (5800 57%) train loss: 0.0290, test_loss: 0.0262]\n",
      "[4m 58s (5850 58%) train loss: 0.0547, test_loss: 0.0468]\n",
      "[5m 1s (5900 59%) train loss: 0.0176, test_loss: 0.0211]\n",
      "[5m 3s (5950 59%) train loss: 0.0286, test_loss: 0.0349]\n",
      "[5m 6s (6000 60%) train loss: 0.0213, test_loss: 0.0197]\n",
      "[5m 9s (6050 60%) train loss: 0.0245, test_loss: 0.0223]\n",
      "[5m 11s (6100 61%) train loss: 0.0176, test_loss: 0.0168]\n",
      "[5m 14s (6150 61%) train loss: 0.0256, test_loss: 0.0284]\n",
      "[5m 16s (6200 62%) train loss: 0.0167, test_loss: 0.0166]\n",
      "[5m 19s (6250 62%) train loss: 0.0399, test_loss: 0.0284]\n",
      "[5m 21s (6300 63%) train loss: 0.1652, test_loss: 0.1456]\n",
      "[5m 24s (6350 63%) train loss: 0.0480, test_loss: 0.0375]\n",
      "[5m 26s (6400 64%) train loss: 0.0303, test_loss: 0.0290]\n",
      "[5m 29s (6450 64%) train loss: 0.0607, test_loss: 0.0583]\n",
      "[5m 31s (6500 65%) train loss: 0.0539, test_loss: 0.0554]\n",
      "[5m 34s (6550 65%) train loss: 0.0288, test_loss: 0.0225]\n",
      "[5m 36s (6600 66%) train loss: 0.0301, test_loss: 0.0263]\n",
      "[5m 39s (6650 66%) train loss: 0.0527, test_loss: 0.0530]\n",
      "[5m 41s (6700 67%) train loss: 0.0343, test_loss: 0.0340]\n",
      "[5m 44s (6750 67%) train loss: 0.0238, test_loss: 0.0245]\n",
      "[5m 46s (6800 68%) train loss: 0.0765, test_loss: 0.0639]\n",
      "[5m 49s (6850 68%) train loss: 0.1612, test_loss: 0.1745]\n",
      "[5m 51s (6900 69%) train loss: 0.0155, test_loss: 0.0203]\n",
      "[5m 54s (6950 69%) train loss: 0.0208, test_loss: 0.0227]\n",
      "[5m 57s (7000 70%) train loss: 0.0213, test_loss: 0.0260]\n",
      "[5m 59s (7050 70%) train loss: 0.0910, test_loss: 0.1100]\n",
      "[6m 2s (7100 71%) train loss: 0.1507, test_loss: 0.1399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6m 4s (7150 71%) train loss: 0.0413, test_loss: 0.0300]\n",
      "[6m 7s (7200 72%) train loss: 0.0179, test_loss: 0.0187]\n",
      "[6m 9s (7250 72%) train loss: 0.0356, test_loss: 0.0358]\n",
      "[6m 12s (7300 73%) train loss: 0.0805, test_loss: 0.0612]\n",
      "[6m 15s (7350 73%) train loss: 0.0831, test_loss: 0.0804]\n",
      "[6m 17s (7400 74%) train loss: 0.0260, test_loss: 0.0219]\n",
      "[6m 20s (7450 74%) train loss: 0.0236, test_loss: 0.0186]\n",
      "[6m 22s (7500 75%) train loss: 0.0316, test_loss: 0.0334]\n",
      "[6m 25s (7550 75%) train loss: 0.0316, test_loss: 0.0356]\n",
      "[6m 27s (7600 76%) train loss: 0.0116, test_loss: 0.0108]\n",
      "[6m 30s (7650 76%) train loss: 0.0276, test_loss: 0.0285]\n",
      "[6m 32s (7700 77%) train loss: 0.0290, test_loss: 0.0262]\n",
      "[6m 35s (7750 77%) train loss: 0.0198, test_loss: 0.0203]\n",
      "[6m 38s (7800 78%) train loss: 0.0137, test_loss: 0.0247]\n",
      "[6m 40s (7850 78%) train loss: 0.0506, test_loss: 0.0379]\n",
      "[6m 43s (7900 79%) train loss: 0.0195, test_loss: 0.0240]\n",
      "[6m 45s (7950 79%) train loss: 0.1067, test_loss: 0.1225]\n",
      "[6m 48s (8000 80%) train loss: 0.0285, test_loss: 0.0347]\n",
      "[6m 50s (8050 80%) train loss: 0.0115, test_loss: 0.0102]\n",
      "[6m 53s (8100 81%) train loss: 0.0338, test_loss: 0.0295]\n",
      "[6m 55s (8150 81%) train loss: 0.0181, test_loss: 0.0209]\n",
      "[6m 58s (8200 82%) train loss: 0.0365, test_loss: 0.0406]\n",
      "[7m 1s (8250 82%) train loss: 0.0190, test_loss: 0.0163]\n",
      "[7m 3s (8300 83%) train loss: 0.0262, test_loss: 0.0243]\n",
      "[7m 6s (8350 83%) train loss: 0.0166, test_loss: 0.0156]\n",
      "[7m 8s (8400 84%) train loss: 0.0064, test_loss: 0.0089]\n",
      "[7m 11s (8450 84%) train loss: 0.0249, test_loss: 0.0266]\n",
      "[7m 13s (8500 85%) train loss: 0.0864, test_loss: 0.0768]\n",
      "[7m 16s (8550 85%) train loss: 0.0189, test_loss: 0.0166]\n",
      "[7m 19s (8600 86%) train loss: 0.0152, test_loss: 0.0163]\n",
      "[7m 21s (8650 86%) train loss: 0.0394, test_loss: 0.0436]\n",
      "[7m 24s (8700 87%) train loss: 0.0136, test_loss: 0.0136]\n",
      "[7m 26s (8750 87%) train loss: 0.0128, test_loss: 0.0120]\n",
      "[7m 29s (8800 88%) train loss: 0.0163, test_loss: 0.0139]\n",
      "[7m 31s (8850 88%) train loss: 0.0397, test_loss: 0.0398]\n",
      "[7m 34s (8900 89%) train loss: 0.0220, test_loss: 0.0247]\n",
      "[7m 37s (8950 89%) train loss: 0.0121, test_loss: 0.0117]\n",
      "[7m 39s (9000 90%) train loss: 0.0129, test_loss: 0.0161]\n",
      "[7m 42s (9050 90%) train loss: 0.0209, test_loss: 0.0151]\n",
      "[7m 44s (9100 91%) train loss: 0.0200, test_loss: 0.0223]\n",
      "[7m 47s (9150 91%) train loss: 0.0192, test_loss: 0.0153]\n",
      "[7m 50s (9200 92%) train loss: 0.0206, test_loss: 0.0193]\n",
      "[7m 52s (9250 92%) train loss: 0.0263, test_loss: 0.0280]\n",
      "[7m 55s (9300 93%) train loss: 0.0300, test_loss: 0.0290]\n",
      "[7m 57s (9350 93%) train loss: 0.0248, test_loss: 0.0204]\n",
      "[8m 0s (9400 94%) train loss: 0.0478, test_loss: 0.0371]\n",
      "[8m 2s (9450 94%) train loss: 0.0170, test_loss: 0.0179]\n",
      "[8m 5s (9500 95%) train loss: 0.1214, test_loss: 0.1058]\n",
      "[8m 8s (9550 95%) train loss: 0.0280, test_loss: 0.0345]\n",
      "[8m 10s (9600 96%) train loss: 0.0188, test_loss: 0.0135]\n",
      "[8m 13s (9650 96%) train loss: 0.0807, test_loss: 0.0618]\n",
      "[8m 15s (9700 97%) train loss: 0.0344, test_loss: 0.0378]\n",
      "[8m 18s (9750 97%) train loss: 0.0219, test_loss: 0.0170]\n",
      "[8m 21s (9800 98%) train loss: 0.0255, test_loss: 0.0207]\n",
      "[8m 23s (9850 98%) train loss: 0.0094, test_loss: 0.0082]\n",
      "[8m 25s (9900 99%) train loss: 0.0216, test_loss: 0.0241]\n",
      "[8m 28s (9950 99%) train loss: 0.0191, test_loss: 0.0172]\n",
      "[8m 31s (10000 100%) train loss: 0.0462, test_loss: 0.0460]\n"
     ]
    }
   ],
   "source": [
    "#main training loop\n",
    "from rnn.model import RNN\n",
    "from rnn.helpers import time_since\n",
    "rnn = RNN(input_size = 6, hidden_size = hidden_size, output_size = 3, model_type=model_type, \\\n",
    "          n_layers=n_layers,bidir = bidir).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "simple_baseline_losses = []\n",
    "baseline_loss_avg = 0\n",
    "\n",
    "#zero grad for optimizer\n",
    "rnn_optimizer.zero_grad()\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #sample traj_batch trajectories\n",
    "    train_input_data,train_output_data,val_input_data,val_output_data = generate_random_data(traj_batch,metadataset.MTRAIN)\n",
    "    \n",
    "    loss = train(rnn, train_input_data,train_output_data, rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn,val_input_data,val_output_data)\n",
    "    test_loss_avg += test_loss\n",
    "    baseline_loss = eval_test_baseline(val_output_data)\n",
    "    baseline_loss_avg += baseline_loss\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        simple_baseline_losses.append(baseline_loss_avg/plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        baseline_loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff8547e8b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff87c08aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "epochs = np.arange(len(all_losses))*plot_every\n",
    "plt.figure()\n",
    "handle1, = plt.plot(epochs,all_losses,label = 'training')\n",
    "handle2, = plt.plot(epochs,test_losses, color='r',label = 'testing')\n",
    "# handle2, = plt.plot(epochs,simple_baseline_losses, color='g',label = 'baseline')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5786403\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in rnn.parameters() if p.requires_grad )\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(),'RNN_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b8b5728628d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbidir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbidir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RNN_1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "rnn = RNN(input_size = 6, hidden_size = hidden_size, output_size = 3, model_type=model_type, \\\n",
    "          n_layers=n_layers,bidir = bidir).to(device)\n",
    "rnn.load_state_dict(torch.load('RNN_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-157efc7198ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraj_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "#For meta-testing, finetune, data\n",
    "n_epochs = 6000\n",
    "traj_batch = 5\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "simple_baseline_losses = []\n",
    "baseline_loss_avg = 0\n",
    "\n",
    "#zero grad for optimizer\n",
    "rnn_optimizer.zero_grad()\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #sample traj_batch trajectories\n",
    "    train_input_data,train_output_data,val_input_data,val_output_data = \\\n",
    "        generate_random_data(traj_batch,metadataset.MTEST)\n",
    "    \n",
    "    loss = train(rnn, train_input_data,train_output_data, rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn,val_input_data,val_output_data)\n",
    "    test_loss_avg += test_loss\n",
    "    baseline_loss = eval_test_baseline(val_output_data)\n",
    "    baseline_loss_avg += baseline_loss\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        simple_baseline_losses.append(baseline_loss_avg/plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0\n",
    "        baseline_loss_avg = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-41868a918b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_output_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_output_data\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mgenerate_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_output_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RMSE:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadataset' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_all_data(all_trajs):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    ---------\n",
    "    generates train and val input and output data in numpy array\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    indeces = np.arange(len(all_trajs))\n",
    "    train_input_data = []\n",
    "    train_output_data = []\n",
    "    val_input_data = []\n",
    "    val_output_data = []\n",
    "    \n",
    "    for i in indeces:\n",
    "        train_input_traj = []\n",
    "        train_output_traj = []\n",
    "        val_input_traj = []\n",
    "        val_output_traj = []\n",
    "        \n",
    "        timesteps,d = all_trajs[i].TrainInput.shape\n",
    "        N = int(d/6)\n",
    "        for j in range(N):\n",
    "            if j == 0:\n",
    "                train_input_traj.append(all_trajs[i].TrainInput[:,-6:])\n",
    "                train_output_traj.append(all_trajs[i].TrainOutput[:,-3:])\n",
    "                val_input_traj.append(all_trajs[i].ValInput[:,-6:])\n",
    "                val_output_traj.append(all_trajs[i].ValOutput[:,-3:])\n",
    "            else:\n",
    "                train_input_traj.append(all_trajs[i].TrainInput[:,(j-1)*6:j*6])\n",
    "                train_output_traj.append(all_trajs[i].TrainOutput[:,(j-1)*3:j*3])\n",
    "                val_input_traj.append(all_trajs[i].ValInput[:,(j-1)*6:j*6])\n",
    "                val_output_traj.append(all_trajs[i].ValOutput[:,(j-1)*3:j*3])\n",
    "        train_input_data.append(train_input_traj)\n",
    "        train_output_data.append(train_output_traj)\n",
    "        val_input_data.append(val_input_traj)\n",
    "        val_output_data.append(val_output_traj)\n",
    "        \n",
    "    return train_input_data,train_output_data,val_input_data,val_output_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_input_data,train_output_data,val_input_data,val_output_data = \\\n",
    "    generate_all_data(metadataset.MTEST)\n",
    "loss = eval_test(rnn,val_input_data,val_output_data)\n",
    "print('RMSE:',torch.sqrt(loss))\n",
    "torch.save(rnn.state_dict(),'RNN_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-367e3b621cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbidir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbidir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RNN_2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_pushing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_horiz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
